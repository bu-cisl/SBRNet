{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0002c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "import math\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a92c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model class\n",
    "sqrt2 = 1.414\n",
    "numViews = 9\n",
    "\n",
    "class resblock(nn.Module):\n",
    "    def __init__(self,channels = 48):\n",
    "        super(resblock,self).__init__()\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1,bias=False)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,nonlinearity='relu')\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1,bias=False)\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,nonlinearity='relu')\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        \n",
    "    def forward(self,x1):\n",
    "        x1 = self.conv1(x1)\n",
    "        x1 = F.relu(self.bn1(x1),inplace=True)\n",
    "        x1 = self.conv2(x1)\n",
    "        return (self.bn2(x1))\n",
    "\n",
    "class cm2netblock(nn.Module):\n",
    "    def __init__(self,inchannels, numblocks, outchannels = 48):\n",
    "        super(cm2netblock,self).__init__()\n",
    "        self.inchannels = inchannels\n",
    "        self.outchannels = outchannels\n",
    "        self.numblocks = numblocks\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(inchannels,outchannels,kernel_size=3,padding=1)\n",
    "        torch.nn.init.kaiming_normal_(self.conv1.weight,nonlinearity='relu')\n",
    "        self.resblocks = nn.ModuleList([resblock() for i in range(numblocks)])\n",
    "        self.conv2 = nn.Conv2d(outchannels,outchannels,kernel_size=3,padding=1)\n",
    "        torch.nn.init.kaiming_normal_(self.conv2.weight,nonlinearity='relu')\n",
    "            \n",
    "    def forward(self,x):\n",
    "        x0 = (self.conv1(x)) \n",
    "        x1 = torch.clone(x0)\n",
    "        for _, modulee in enumerate(self.resblocks):\n",
    "            x1 = (modulee(x1) + x1)/sqrt2 # short residual connection \n",
    "        x1 = (x1 + x0)/sqrt2 # long residual connection\n",
    "        return self.conv2(x1)\n",
    "            \n",
    "class cm2net(nn.Module):\n",
    "    def __init__(self,numBlocks, stackchannels = numViews, rfvchannels = 24, outchannels = 24):\n",
    "        super(cm2net,self).__init__()\n",
    "        \n",
    "        self.stackpath = cm2netblock(stackchannels, numblocks = numBlocks)\n",
    "        self.rfvpath = cm2netblock(rfvchannels, numblocks = numBlocks)\n",
    "        self.endconv = nn.Conv2d(outchannels*2,outchannels, kernel_size=3, padding=1)\n",
    "        torch.nn.init.kaiming_normal_(self.endconv.weight,nonlinearity='relu')\n",
    "        \n",
    "    def forward(self,stack,rfv):\n",
    "        return self.endconv((self.stackpath(stack)+self.rfvpath(rfv))/sqrt2) # branch fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe66a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dataloader\n",
    "class Dataset(td.Dataset):\n",
    "    \n",
    "    def __init__(self, folder):\n",
    "        super(Dataset, self).__init__()\n",
    "        self.directory = folder # requires a forward slash at the end\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        DIR = self.directory+\"rfvbg\" # rfbg refers to the refocused volume with background\n",
    "        return (len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        stack = io.imread(self.directory+\"stackbg/sim_meas_\"+str(index)+\".tif\")\n",
    "        stack = (stack - stack.min()) / (stack.max() - stack.min()).astype(np.int16) \n",
    "        stack = torch.from_numpy(stack) \n",
    "        \n",
    "        rfv = io.imread(self.directory+\"rfvbg/sim_meas_\"+str(index)+\".tif\")\n",
    "        rfv = (rfv - rfv.min()) / (rfv.max() - rfv.min()).astype(np.int16) \n",
    "        rfv = torch.from_numpy(rfv) \n",
    "        \n",
    "        gt = io.imread(self.directory+\"gt/sim_gt_vol_\"+str(index)+\".tif\")\n",
    "        gt = (gt - gt.min()) / (gt.max() - gt.min()).astype(np.int16) \n",
    "        gt = torch.from_numpy(gt)\n",
    "        \n",
    "        return stack, rfv, gt\n",
    "\n",
    "class my_subset(Dataset):\n",
    "\n",
    "    def __init__(self, dataset,isVal):\n",
    "        self.dataset = dataset\n",
    "        self.isVal = isVal\n",
    "    def __getitem__(self, idx):\n",
    "        p = 224\n",
    "        \n",
    "        # a and b parameters for poisson gaussian noise calibrated from experiment\n",
    "#         amin = 1.49e-4 - 5.7092e-5\n",
    "#         amax = 1.49e-4 + 5.7092e-5\n",
    "#         bmin = 5.41e-6 - 2.7754e-6\n",
    "#         bmax = 5.41e-6 + 2.7754e-6\n",
    "#         aa = torch.rand(1)*(amax-amin)+amin \n",
    "#         bb = torch.rand(1)*(bmax-bmin)+bmin \n",
    "        \n",
    "        aa = torch.randn(1)*5.7092e-5 + 1.49e-4\n",
    "        bb = torch.randn(1)*2.7754e-6 + 5.41e-6\n",
    "        # if during validation, feed in the entire 512x512 data\n",
    "        if self.isVal: \n",
    "            stack, rfv, gt = self.dataset.__getitem__(idx)\n",
    "            stack += torch.sqrt(aa*stack+bb)*torch.randn(stack.shape) \n",
    "            rfv += torch.sqrt(aa*rfv+bb)*torch.randn(rfv.shape)/3 \n",
    "            return stack, rfv, gt\n",
    "        #if during training, get random 224x224 patches\n",
    "        else:\n",
    "            stack, rfv, gt = self.dataset.__getitem__(idx)\n",
    "            dim = stack.shape\n",
    "            a = torch.randint(0,dim[1]-p,(1,))\n",
    "            b = torch.randint(0,dim[2]-p,(1,))\n",
    "\n",
    "            stack = stack[:,a:a+p,b:b+p]\n",
    "            stack += torch.sqrt(aa*stack+bb)*torch.randn(stack.shape) \n",
    "            rfv = rfv[:,a:a+p,b:b+p]\n",
    "            rfv += torch.sqrt(aa*rfv+bb)*torch.randn(rfv.shape)/3\n",
    "            return stack , rfv, gt[:,a:a+p,b:b+p]\n",
    "    def __len__(self):\n",
    "        return self.dataset.__len__()\n",
    "\n",
    "d_traindata = './training data/dataset11/'\n",
    "\n",
    "completedataset = Dataset(d_traindata)\n",
    "train_size = int(0.8 * len(completedataset))\n",
    "test_size = int(0.2*len(completedataset))\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(completedataset, [train_size, test_size])\n",
    "val_dataset = my_subset(val_dataset,True)\n",
    "train_dataset = my_subset(train_dataset,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "layers = 20\n",
    "net = cm2net(numBlocks = layers).to(device)\n",
    "\n",
    "\n",
    "#if torch.cuda.device_count() > 1:\n",
    "#    \n",
    "#    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "#    net = nn.DataParallel(net)\n",
    "\n",
    "batchNumber = 12\n",
    "notes = 'sbrnet_'\n",
    "numEpoch = 10000\n",
    "lr = 1e-3\n",
    "bestValLoss = math.inf\n",
    "def count_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "numparam = count_parameters(net)\n",
    "notessave = 'cosine annealing scheduler start at 1e-3 and relu act function'\n",
    "\n",
    "trainloader = td.DataLoader(train_dataset, batch_size=batchNumber, shuffle=True, pin_memory=True)\n",
    "valloader = td.DataLoader(val_dataset, batch_size=batchNumber, shuffle=True, pin_memory=True)\n",
    "\n",
    "modelname = 'cm2net_'+notes+'layers_'+str(layers)\n",
    "#d_trainedmodels = 'H:/jeffrey/scattering/models/test/'\n",
    "d_trainedmodels = './models/'\n",
    "\n",
    "# feat_list = ['r11','r21','r31','r41','r51']\n",
    "# feat_weight = torch.tensor([1/32, 1/16, 1/8, 1/4, 1])\n",
    "# VGG19 = VGG19Transfer().to(device)\n",
    "losshistory = []\n",
    "trainhistory = []\n",
    "valhistory = []\n",
    "optimizer = torch.optim.Adam(net.parameters(),lr=lr,betas=(0.9, 0.999))\n",
    "# optimizer = torch.optim.SGD(netrfv.parameters(),lr=lr)\n",
    "\n",
    "#### uncomment if continuing training ####\n",
    "#path = d_trainedmodels+modelname\n",
    "#checkpoint2 = torch.load(path)\n",
    "#net.load_state_dict(checkpoint2['net_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint2['optimizer_state_dict'])\n",
    "#trainhistory = checkpoint2['trainloss']\n",
    "#valhistory = checkpoint2['valloss']\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,30)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "# criterionl1 = nn.L1Loss()\n",
    "starto = time.time()\n",
    "\n",
    "startepoch = 0\n",
    "for epoch in range(numEpoch):\n",
    "    s = time.time()\n",
    "    trainloss = 0\n",
    "    valloss = 0\n",
    "    numtrainloader = len(trainloader)\n",
    "    numvalloader = len(valloader)\n",
    "    net.train()\n",
    "    for stack, rfv, gt in trainloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        stack, rfv, gt = stack.to(device), rfv.to(device), gt.to(device)\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            stack = stack.half()\n",
    "            rfv = rfv.half()\n",
    "            gt = gt.half()\n",
    "            \n",
    "            out = net(stack,rfv)\n",
    "\n",
    "            loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        if epoch == 0: print(loss)\n",
    "        if not torch.isnan(loss):\n",
    "            lo = loss.detach().cpu()\n",
    "            losshistory.append(lo)\n",
    "            trainloss = trainloss + lo\n",
    "        else:\n",
    "            numtrainloader = numtrainloader - 1\n",
    "    \n",
    "    if numtrainloader == 0:\n",
    "        trainloss = float(\"NaN\")\n",
    "        \n",
    "    else:\n",
    "        trainloss = trainloss/numtrainloader\n",
    "        trainhistory.append(trainloss)\n",
    "        \n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for stack, rfv, gt in valloader:\n",
    "            \n",
    "            stack, rfv, gt = stack.to(device), rfv.to(device), gt.to(device)\n",
    "            with torch.cuda.amp.autocast(enabled=True):\n",
    "                stack = stack.half()\n",
    "                rfv = rfv.half()\n",
    "                gt = gt.half()\n",
    "                out = net(stack,rfv)\n",
    "\n",
    "                loss = F.binary_cross_entropy_with_logits(out, gt)\n",
    "                \n",
    "            if not torch.isnan(loss):\n",
    "                valloss = valloss + loss.detach().cpu()\n",
    "            else:\n",
    "                 numvalloader = numvalloader - 1   \n",
    "                    \n",
    "    t = time.time() - s\n",
    "            \n",
    "    if numvalloader == 0:\n",
    "        valloss = float(\"NaN\")\n",
    "        continue\n",
    "    else:\n",
    "        valloss = valloss / numvalloader\n",
    "        valhistory.append(valloss.detach().cpu())\n",
    "        \n",
    "    if valloss < bestValLoss:\n",
    "\n",
    "        tt = time.time() - starto\n",
    "        bestValLoss = valloss\n",
    "        torch.save({\n",
    "                'epoch': epoch,\n",
    "                'net_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'valloss': valhistory,\n",
    "                'trainloss': trainhistory,\n",
    "                'lr': lr,\n",
    "                'notes': notessave,\n",
    "                'dir': d_traindata,\n",
    "                'time': tt,\n",
    "                'batchsize': batchNumber,\n",
    "                'num_network_param': numparam,\n",
    "                }, d_trainedmodels+modelname) \n",
    "    scheduler.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
